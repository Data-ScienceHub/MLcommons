[rank: 0] Global seed set to 7
2023-02-13 22:44:18.999936: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-13 22:44:19.680951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs
2023-02-13 22:44:19.681036: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-02-13 22:44:19.754759: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-02-13 22:44:21.438891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs
2023-02-13 22:44:21.439098: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs
2023-02-13 22:44:21.439124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: ../scratch/AGE6579/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name                               | Type                            | Params
----------------------------------------------------------------------------------------
0  | loss                               | MultiLoss                       | 0     
1  | logging_metrics                    | ModuleList                      | 0     
2  | input_embeddings                   | MultiEmbedding                  | 0     
3  | prescalers                         | ModuleDict                      | 64    
4  | static_variable_selection          | VariableSelectionNetwork        | 528   
5  | encoder_variable_selection         | VariableSelectionNetwork        | 1.8 K 
6  | decoder_variable_selection         | VariableSelectionNetwork        | 528   
7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K 
8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K 
9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K 
10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K 
11 | lstm_encoder                       | LSTM                            | 2.2 K 
12 | lstm_decoder                       | LSTM                            | 2.2 K 
13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   
14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    
15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K 
16 | multihead_attn                     | InterpretableMultiHeadAttention | 676   
17 | post_attn_gate_norm                | GateAddNorm                     | 576   
18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K 
19 | pre_output_gate_norm               | GateAddNorm                     | 576   
20 | output_layer                       | Linear                          | 17    
----------------------------------------------------------------------------------------
16.5 K    Trainable params
0         Non-trainable params
16.5 K    Total params
0.066     Total estimated model params size (MB)
Metric val_loss improved. New best score: 0.412
Monitored metric val_loss did not improve in the last 3 records. Best score: 0.412. Signaling Trainer to stop.
cuda
(2584600, 13)
Static features ['AGE019', 'AGE2029', 'AGE3039', 'AGE4049', 'AGE5064', 'AGE6579', 'AGE80PLUS'].   Choosing feature AGE6579.
There are 3224 unique counties in the dataset.
Train samples 2039744, validation samples 90272, test samples 90272
640 days of training, 15 days of validation data, 15 days of test data.
Scaling static and dynamic input features: ['AGE6579', 'VaccinationFull']
Scaling targets ['Cases']
Number of parameters in network: 16.5k

----Training started at 2023-02-13 22:44:23.610484----


----Training ended at 2023-02-14 01:45:13.791460, elapsed time 3:00:50.180976
Best model by validation loss saved at /gpfs/gpfs0/project/SDS/capstones/sdscap-ds6013/MLcommons/TFT-pytorch/scratch/AGE6579/checkpoints/best-epoch=0.ckpt
Creating folder ../scratch/AGE6579/figures
Loading best model from /gpfs/gpfs0/project/SDS/capstones/sdscap-ds6013/MLcommons/TFT-pytorch/scratch/AGE6579/checkpoints/best-epoch=0.ckpt

---Training prediction--


Train raw prediction shapes

prediction list of length 1 torch.Size([1952640, 15, 1])
encoder_attention torch.Size([1952640, 15, 4, 13])
decoder_attention torch.Size([1952640, 15, 4, 15])
static_variables torch.Size([1952640, 1, 1])
encoder_variables torch.Size([1952640, 13, 1, 3])
decoder_variables torch.Size([1952640, 15, 1, 1])
decoder_lengths torch.Size([1952640])
encoder_lengths torch.Size([1952640])

---Training results--

Target Cases, MAE 10.457, RMSE 58.876, RMSLE 0.91029, SMAPE 0.74462. NNSE 0.83292.


---Validation results--

Target Cases, MAE 18.705, RMSE 84.75, RMSLE 1.1995, SMAPE 0.8236. NNSE 0.74243.


---Test results--

Target Cases, MAE 35.897, RMSE 228.42, RMSLE 1.3421, SMAPE 0.85981. NNSE 0.65895.

Ended at 2023-02-14 02:13:17.714016. Elapsed time 3:28:54.103558
